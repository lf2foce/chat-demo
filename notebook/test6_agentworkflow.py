from llama_index.llms.google_genai import GoogleGenAI
from llama_index.indices.managed.llama_cloud import LlamaCloudIndex
from llama_index.core import Settings
from llama_index.core.tools import QueryEngineTool, ToolMetadata
from llama_index.core.workflow import Event, StartEvent, StopEvent, Workflow, step, Context
from typing import List, Dict, Any
import os
import asyncio
from datetime import datetime
from dotenv import load_dotenv
load_dotenv()

# ===== EVENTS DEFINITION =====
class SearchEvent(Event):
    """Event ch·ª©a k·∫øt qu·∫£ t√¨m ki·∫øm"""
    query: str
    results: List[str]
    success: bool

# ===== OPTIMIZED RAG WORKFLOW =====
class OptimizedRAGWorkflow(Workflow):
    """T·ªëi ∆∞u h√≥a RAG Workflow ƒë·ªÉ tr√°nh timeout"""
    
    def __init__(self, query_engine_tool: QueryEngineTool):
        super().__init__(timeout=30.0)  # Gi·∫£m timeout
        self.query_engine_tool = query_engine_tool
        self.llm = Settings.llm
    
    @step
    async def search_and_synthesize(self, ctx: Context, ev: StartEvent) -> StopEvent:
        """T√¨m ki·∫øm v√† t·ªïng h·ª£p tr·ª±c ti·∫øp ƒë·ªÉ tr√°nh timeout"""
        query = ev.query
        start_time = datetime.now()
        
        print(f"üîç T√¨m ki·∫øm: {query}")
        
        try:
            # T√¨m ki·∫øm tr·ª±c ti·∫øp
            response = await self.query_engine_tool.query_engine.aquery(query)
            print(response)
            # T·ªïng h·ª£p ng·∫Øn g·ªçn
            synthesis_prompt = f"""
            D·ª±a tr√™n th√¥ng tin sau, h√£y tr·∫£ l·ªùi  c√¢u h·ªèi: {query}
            
            Th√¥ng tin: {str(response)[:1000]}
            
            Tr·∫£ l·ªùi theo format:
            üéØ **Tr·∫£ l·ªùi :**
            [C√¢u tr·∫£ l·ªùi ch√≠nh]
            
            üè´ **Tr∆∞·ªùng ph√π h·ª£p:**
            [Danh s√°ch tr∆∞·ªùng]
            
            üí∞ **H·ªçc ph√≠:**
            [Th√¥ng tin h·ªçc ph√≠]
            """
            
            final_response = await self.llm.acomplete(synthesis_prompt)
            
            total_time = (datetime.now() - start_time).total_seconds()
            result = f"{str(final_response)}\n\n‚è±Ô∏è Th·ªùi gian: {total_time:.1f}s"
            
            print(f"‚úÖ Ho√†n th√†nh trong {total_time:.1f}s")
            return StopEvent(result=result)
            
        except Exception as e:
            print(f"‚ùå L·ªói: {e}")
            return StopEvent(result=f"L·ªói x·ª≠ l√Ω: {str(e)}")
    


# ===== MAIN EXECUTION =====
async def main():
    """H√†m ch√≠nh ƒë·ªÉ ch·∫°y Optimized RAG Workflow"""
    
    # C·∫•u h√¨nh LLM
    llm = GoogleGenAI(model="gemini-2.0-flash")
    Settings.llm = llm
    
    try:
        # Kh·ªüi t·∫°o index
        print("üöÄ Kh·ªüi t·∫°o LlamaCloud Index...")
        index_dsdaihoc = LlamaCloudIndex(
            name="dsdaihoc",
            project_name="Default",
            organization_id="1bcf5fb2-bd7d-4c76-b6d5-bb793486e1b3",
            api_key=os.getenv("LLAMA_CLOUD_API_KEY"),
        )
        
        # T·∫°o query engine tool
        qe = index_dsdaihoc.as_query_engine(similarity_top_k=3)  # Gi·∫£m s·ªë l∆∞·ª£ng
        query_engine_tool = QueryEngineTool(
            query_engine=qe,
            metadata=ToolMetadata(
                name="dsdaihoc",
                description="Danh s√°ch c√°c tr∆∞·ªùng ƒë·∫°i h·ªçc ·ªü vi·ªát nam",
            ),
        )
        
        # Kh·ªüi t·∫°o Optimized RAG Workflow
        print("ü§ñ Kh·ªüi t·∫°o Optimized RAG Workflow...")
        workflow = OptimizedRAGWorkflow(query_engine_tool)
        
        # Ch·∫°y workflow
        print("\nüéØ B·∫ÆT ƒê·∫¶U WORKFLOW")
        
        query = "H·ªçc tr∆∞·ªùng kinh t·∫ø n√†o ·ªü C·∫ßu Gi·∫•y, h·ªçc ph√≠ d∆∞·ªõi 2 tri·ªáu/th√°ng, ng√†nh t√†i ch√≠nh ng√¢n h√†ng v√† c√≥ tri·ªÉn v·ªçng khi ra tr∆∞·ªùng"
        
        result = await workflow.run(query=query)
        
        print("\nüìã K·∫æT QU·∫¢:")
        print(result)
        
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())