{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f1eeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enhanced chat router with retriever approach\n",
    "import os\n",
    "import re\n",
    "import asyncio\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from fastapi import FastAPI, HTTPException, Header\n",
    "from fastapi import APIRouter\n",
    "from fastapi.responses import StreamingResponse\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from llama_index.core import Settings \n",
    "from llama_index.indices.managed.llama_cloud import LlamaCloudIndex \n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "# from llama_index.llms.groq import Groq\n",
    "# from llama_index.llms.cerebras import Cerebras\n",
    "# from llama_index.llms.together import TogetherLLM\n",
    "# from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.storage.chat_store import SimpleChatStore\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool, FunctionTool\n",
    "from llama_index.core.agent.workflow import ReActAgent\n",
    "from llama_index.core.workflow import Context\n",
    "\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8eb81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Index global - chá»‰ khá»Ÿi táº¡o 1 láº§n\n",
    "index_dsdaihoc = LlamaCloudIndex(\n",
    "        name=\"dsdaihoc\",\n",
    "        project_name=\"Default\",\n",
    "        organization_id=\"1bcf5fb2-bd7d-4c76-b6d5-bb793486e1b3\",\n",
    "        api_key=os.getenv(\"LLAMA_CLOUD_API_KEY\"),\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2ï¸âƒ£ Setup tools\n",
    "qe = index_dsdaihoc.as_query_engine(similarity_top_k=5)\n",
    "rag_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=qe,\n",
    "    name=\"RAG\",\n",
    "    description=\"ThÃ´ng tin cÃ¡c trÆ°á»ng Ä‘áº¡i há»c táº¡i Viá»‡t Nam\"\n",
    ")\n",
    "\n",
    "def score_program(\n",
    "    user_gpa: float,\n",
    "    desired_program: str,\n",
    "    budget: float,\n",
    "    location_pref: str,\n",
    "    candidate_program: dict\n",
    ") -> dict:\n",
    "    \"\"\"TÃ­nh Ä‘iá»ƒm cho cÃ¡c chÆ°Æ¡ng trÃ¬nh dá»±a trÃªn thÃ´ng tin ngÆ°á»i dÃ¹ng.\"\"\"\n",
    "    score = 0\n",
    "    reasons = []\n",
    "    \n",
    "    if user_gpa >= candidate_program.get(\"cutoff_gpa\", 0):\n",
    "        score += 5\n",
    "        reasons.append(\"GPA Ä‘áº¡t yÃªu cáº§u\")\n",
    "    \n",
    "    if candidate_program.get(\"tuition_per_month\", 0)/1e6 <= budget:\n",
    "        score += 3\n",
    "        reasons.append(\"Trong ngÃ¢n sÃ¡ch\")\n",
    "    \n",
    "    if location_pref.lower() in candidate_program.get(\"location\", \"\").lower():\n",
    "        score += 2\n",
    "        reasons.append(\"Gáº§n khu vá»±c\")\n",
    "    \n",
    "    if desired_program.lower() in [p.lower() for p in candidate_program.get(\"programs\", [])]:\n",
    "        score += 4\n",
    "        reasons.append(\"CÃ³ ngÃ nh báº¡n muá»‘n\")\n",
    "    \n",
    "    return {\n",
    "        \"program_name\": candidate_program.get(\"name\"), \n",
    "        \"score\": score, \n",
    "        \"reasons\": reasons\n",
    "    }\n",
    "\n",
    "score_tool = FunctionTool.from_defaults(\n",
    "    fn=score_program,\n",
    "    name=\"ScoreProgram\",\n",
    "    description=\"Score a candidate program for a student based on GPA, program, budget, and location preferences\"\n",
    ")\n",
    "\n",
    "# 6ï¸âƒ£ Táº¡o agent ReAct vá»›i cáº£ 2 tools\n",
    "agent = ReActAgent(\n",
    "    tools=[rag_tool, score_tool],\n",
    "    llm=Settings.llm,\n",
    "    verbose=True\n",
    ")\n",
    "ctx = Context(agent)\n",
    "\n",
    "agent.run(\"CÃ³ 10 triá»‡u 1 thÃ¡ng nÃªn há»c ngÃ nh kinh táº¿ nÃ o á»Ÿ HÃ  Ná»™i\", ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "242eb70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step init_run\n",
      "Step init_run produced event AgentInput\n",
      "Running step setup_agent\n",
      "Step setup_agent produced event AgentSetup\n",
      "Running step run_agent_step\n",
      "Thought: I need to use a tool to help me answer the question.\n",
      "\n",
      "Action: ScoreProgram\n",
      "Action Input: {\"user_gpa\": 0, \"desired_program\": \"Kinh táº¿\", \"budget\": 10000000, \"location_pref\": \"HÃ  Ná»™i\", \"candidate_program\": {}}Step run_agent_step produced event AgentOutput\n",
      "Running step parse_agent_output\n",
      "Step parse_agent_output produced no event\n",
      "Running step call_tool\n",
      "Step call_tool produced event ToolCallResult\n",
      "Running step aggregate_tool_results\n",
      "Step aggregate_tool_results produced event AgentInput\n",
      "Running step setup_agent\n",
      "Step setup_agent produced event AgentSetup\n",
      "Running step run_agent_step\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Vá»›i ngÃ¢n sÃ¡ch 10 triá»‡u má»™t thÃ¡ng vÃ  mong muá»‘n há»c ngÃ nh Kinh táº¿ táº¡i HÃ  Ná»™i, báº¡n cÃ³ thá»ƒ xem xÃ©t cÃ¡c trÆ°á»ng cÃ³ chÆ°Æ¡ng trÃ¬nh phÃ¹ há»£p vá»›i GPA cá»§a báº¡n vÃ  náº±m trong ngÃ¢n sÃ¡ch.Step run_agent_step produced event AgentOutput\n",
      "Running step parse_agent_output\n",
      "Step parse_agent_output produced event StopEvent\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent.workflow import ToolCallResult, AgentStream\n",
    "\n",
    "handler = agent.run(\"CÃ³ 10 triá»‡u 1 thÃ¡ng nÃªn há»c ngÃ nh kinh táº¿ nÃ o á»Ÿ HÃ  Ná»™i\", ctx=ctx)\n",
    "\n",
    "async for ev in handler.stream_events():\n",
    "    # if isinstance(ev, ToolCallResult):\n",
    "    #     print(f\"\\nCall {ev.tool_name} with {ev.tool_kwargs}\\nReturned: {ev.tool_output}\")\n",
    "    if isinstance(ev, AgentStream):\n",
    "        print(f\"{ev.delta}\", end=\"\", flush=True)\n",
    "\n",
    "response = await handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a84f6f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT=\"\"\" Báº¡n lÃ  má»™t tÆ° váº¥n viÃªn giÃ¡o dá»¥c chuyÃªn nghiá»‡p, giÃºp há»c sinh tÃ¬m trÆ°á»ng Ä‘áº¡i há»c phÃ¹ há»£p.\n",
    "\n",
    "NHIá»†M Vá»¤ CHÃNH:\n",
    "1. Sá»­ dá»¥ng tool RAG Ä‘á»ƒ tÃ¬m thÃ´ng tin cÃ¡c trÆ°á»ng Ä‘áº¡i há»c tá»« database\n",
    "2. Sá»­ dá»¥ng tool ScoreProgram Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ phÃ¹ há»£p cá»§a tá»«ng chÆ°Æ¡ng trÃ¬nh\n",
    "3. ÄÆ°a ra lá»i khuyÃªn cá»¥ thá»ƒ dá»±a trÃªn tiÃªu chÃ­ cá»§a há»c sinh\n",
    "\n",
    "QUY TRÃŒNH Láº¬P LUáº¬N:\n",
    "1. TrÆ°á»›c tiÃªn, hÃ£y sá»­ dá»¥ng tool RAG Ä‘á»ƒ tÃ¬m cÃ¡c trÆ°á»ng/chÆ°Æ¡ng trÃ¬nh liÃªn quan\n",
    "2. Vá»›i má»—i chÆ°Æ¡ng trÃ¬nh tÃ¬m Ä‘Æ°á»£c, sá»­ dá»¥ng tool ScoreProgram Ä‘á»ƒ tÃ­nh Ä‘iá»ƒm phÃ¹ há»£p\n",
    "3. Sáº¯p xáº¿p theo Ä‘iá»ƒm sá»‘ vÃ  Ä‘Æ°a ra top 3-5 gá»£i Ã½ tá»‘t nháº¥t\n",
    "4. Giáº£i thÃ­ch lÃ½ do táº¡i sao má»—i lá»±a chá»n phÃ¹ há»£p\n",
    "\n",
    "NGUYÃŠN Táº®C:\n",
    "- LuÃ´n sá»­ dá»¥ng tools trÆ°á»›c khi Ä‘Æ°a ra lá»i khuyÃªn\n",
    "- KhÃ´ng bá»‹a Ä‘áº·t thÃ´ng tin vá» trÆ°á»ng Ä‘áº¡i há»c\n",
    "- Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t\n",
    "- Thá»ƒ hiá»‡n sá»± Ä‘á»“ng cáº£m vÃ  há»— trá»£ tÃ­ch cá»±c\"\"\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd44400a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ReActAgent' object has no attribute '_get_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 78\u001b[0m\n\u001b[1;32m     60\u001b[0m memory \u001b[38;5;241m=\u001b[39m ChatMemoryBuffer\u001b[38;5;241m.\u001b[39mfrom_defaults(token_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1500\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# # 6ï¸âƒ£ Táº¡o Agent theo kiá»ƒu ReAct cÃ³ thá»ƒ gá»i cáº£ RAG vÃ  tÃ­nh Ä‘iá»ƒm\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# agent = ReActAgent(\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#     tools=[rag_tool, score_tool],\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m \n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# 7ï¸âƒ£ Táº¡o context vÃ  cháº¡y agent vá»›i cÃ¢u há»i cá»§a báº¡n\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m ctx \u001b[38;5;241m=\u001b[39m \u001b[43mContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m response \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCÃ³ 10 triá»‡u 1 thÃ¡ng nÃªn há»c ngÃ nh kinh táº¿ nÃ o á»Ÿ HÃ  Ná»™i?\u001b[39m\u001b[38;5;124m\"\u001b[39m, ctx\u001b[38;5;241m=\u001b[39mctx)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ab312/lib/python3.12/site-packages/workflows/context/context.py:77\u001b[0m, in \u001b[0;36mContext.__init__\u001b[0;34m(self, workflow, stepwise)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Store the step configs of this workflow, to be used in send_event\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_configs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, StepConfig \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step_name, step_func \u001b[38;5;129;01min\u001b[39;00m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_steps\u001b[49m()\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_configs[step_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(step_func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__step_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Init broker machinery\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ReActAgent' object has no attribute '_get_steps'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.tools import QueryEngineTool, FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.workflow import Context\n",
    "from llama_index.core.agent.workflow import AgentWorkflow\n",
    "\n",
    "# 1ï¸âƒ£ Configure global LLM vÃ  embedding model\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "Settings.embed_model = OpenAIEmbedding()\n",
    "\n",
    "# # 2ï¸âƒ£ Táº¡o vÃ  index dá»¯ liá»‡u Ä‘áº¡i há»c (vÃ­ dá»¥ náº±m trong ./data_daihoc)\n",
    "# documents = SimpleDirectoryReader(\"./data_daihoc\").load_data()\n",
    "# index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# Index global - chá»‰ khá»Ÿi táº¡o 1 láº§n\n",
    "index_dsdaihoc = LlamaCloudIndex(\n",
    "        name=\"dsdaihoc\",\n",
    "        project_name=\"Default\",\n",
    "        organization_id=\"1bcf5fb2-bd7d-4c76-b6d5-bb793486e1b3\",\n",
    "        api_key=os.getenv(\"LLAMA_CLOUD_API_KEY\"),\n",
    "        )\n",
    "# 3ï¸âƒ£ Build query engine (RAG engine)\n",
    "query_engine = index_dsdaihoc.as_query_engine(similarity_top_k=5)\n",
    "\n",
    "# 4ï¸âƒ£ Wrap nÃ³ thÃ nh má»™t tool Ä‘á»ƒ agent cÃ³ thá»ƒ gá»i\n",
    "rag_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"RAG\",\n",
    "    description=\"ThÃ´ng tin cÃ¡c trÆ°á»ng Ä‘áº¡i há»c táº¡i Viá»‡t Nam\"\n",
    ")\n",
    "\n",
    "# 5ï¸âƒ£ Tool cháº¥m Ä‘iá»ƒm chÆ°Æ¡ng trÃ¬nh nhÆ° báº¡n cÃ³\n",
    "def score_program(user_gpa: float, desired_program: str, budget: float, location_pref: str, candidate_program: dict) -> dict:\n",
    "    score = 0\n",
    "    reasons = []\n",
    "    if user_gpa >= candidate_program.get(\"cutoff_gpa\", 0):\n",
    "        score += 5; reasons.append(\"GPA Ä‘áº¡t yÃªu cáº§u\")\n",
    "    if candidate_program.get(\"tuition_per_month\", 0) / 1e6 <= budget:\n",
    "        score += 3; reasons.append(\"Trong ngÃ¢n sÃ¡ch\")\n",
    "    if location_pref.lower() in candidate_program.get(\"location\", \"\").lower():\n",
    "        score += 2; reasons.append(\"Gáº§n khu vá»±c\")\n",
    "    if desired_program.lower() in [p.lower() for p in candidate_program.get(\"programs\", [])]:\n",
    "        score += 4; reasons.append(\"CÃ³ ngÃ nh báº¡n muá»‘n\")\n",
    "    return {\n",
    "        \"program_name\": candidate_program.get(\"name\"),\n",
    "        \"score\": score,\n",
    "        \"reasons\": reasons\n",
    "    }\n",
    "\n",
    "score_tool = FunctionTool.from_defaults(\n",
    "    fn=score_program,\n",
    "    name=\"ScoreProgram\",\n",
    "    description=\"Cháº¥m Ä‘iá»ƒm chÆ°Æ¡ng trÃ¬nh Ä‘áº¡i há»c dá»±a trÃªn GPA, ngÃ nh, ngÃ¢n sÃ¡ch, nÆ¡i á»Ÿ\"\n",
    ")\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=1500)\n",
    "\n",
    "# # 6ï¸âƒ£ Táº¡o Agent theo kiá»ƒu ReAct cÃ³ thá»ƒ gá»i cáº£ RAG vÃ  tÃ­nh Ä‘iá»ƒm\n",
    "# agent = ReActAgent(\n",
    "#     tools=[rag_tool, score_tool],\n",
    "#     llm=Settings.llm,\n",
    "#     verbose=True,\n",
    "#     memory=memory,\n",
    "    \n",
    "# )\n",
    "# agent = ReActAgent.from_tools(\n",
    "#     tools=[rag_tool, score_tool],\n",
    "#     llm=Settings.llm,\n",
    "#     verbose=True,\n",
    "#     context=\"Báº¡n lÃ  trá»£ lÃ½ tÆ° váº¥n Ä‘áº¡i há»c táº¡i Viá»‡t Nam.\",\n",
    "# )\n",
    "\n",
    "# 7ï¸âƒ£ Táº¡o context vÃ  cháº¡y agent vá»›i cÃ¢u há»i cá»§a báº¡n\n",
    "ctx = Context(agent)\n",
    "response = agent.run(\"CÃ³ 10 triá»‡u 1 thÃ¡ng nÃªn há»c ngÃ nh kinh táº¿ nÃ o á»Ÿ HÃ  Ná»™i?\", ctx=ctx)\n",
    "\n",
    "print(response)\n",
    "\n",
    "workflow = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[rag_tool, score_tool],\n",
    "    llm=Settings.llm,\n",
    "    system_prompt=\"Báº¡n lÃ  trá»£ lÃ½ tÆ° váº¥n...\",  # prompt tuá»³ biáº¿n\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "ctx = Context(workflow)\n",
    "response = workflow.run(\"CÃ³ 10 triá»‡u 1 thÃ¡ng nÃªn há»c ngÃ nh kinh táº¿ nÃ o á»Ÿ HÃ  Ná»™i?\", ctx=ctx)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a5f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 3665f99b-3505-4112-b020-a389011122ab. Step input: CÃ³ 10 triá»‡u 1 thÃ¡ng nÃªn há»c ngÃ nh kinh táº¿ nÃ o á»Ÿ HÃ  Ná»™i?\n",
      "\u001b[1;3;38;5;200mThought: The user is asking for a suitable economics program in Hanoi with a budget of 10 million VND per month. I can use the ScoreProgram tool to find a suitable program based on the user's GPA, desired program, budget, and location preference.\n",
      "Action: ScoreProgram\n",
      "Action Input: {'user_gpa': 3.0, 'desired_program': 'Kinh táº¿', 'budget': 10000000, 'location_pref': 'HÃ  Ná»™i', 'candidate_program': AttributedDict()}\n",
      "\u001b[0m\u001b[1;3;34mObservation: {'program_name': None, 'score': 8, 'reasons': ['GPA Ä‘áº¡t yÃªu cáº§u', 'Trong ngÃ¢n sÃ¡ch']}\n",
      "\u001b[0m> Running step 7bb1a6b2-a7be-4c7c-ba35-204a2d3a31d1. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The ScoreProgram tool didn't provide a specific program name, but it did indicate that there are economics programs in Hanoi within the user's budget and suitable for a student with a GPA of 3.0. I can answer without using any more tools.\n",
      "Answer: CÃ³ cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o ngÃ nh Kinh táº¿ á»Ÿ HÃ  Ná»™i phÃ¹ há»£p vá»›i ngÃ¢n sÃ¡ch cá»§a báº¡n vÃ  yÃªu cáº§u vá» GPA. Tuy nhiÃªn, Ä‘á»ƒ cÃ³ thÃ´ng tin cá»¥ thá»ƒ hÆ¡n, báº¡n nÃªn tÃ¬m hiá»ƒu thÃªm tá»« cÃ¡c trÆ°á»ng Ä‘áº¡i há»c cá»¥ thá»ƒ.\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response='CÃ³ cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o ngÃ nh Kinh táº¿ á»Ÿ HÃ  Ná»™i phÃ¹ há»£p vá»›i ngÃ¢n sÃ¡ch cá»§a báº¡n vÃ  yÃªu cáº§u vá» GPA. Tuy nhiÃªn, Ä‘á»ƒ cÃ³ thÃ´ng tin cá»¥ thá»ƒ hÆ¡n, báº¡n nÃªn tÃ¬m hiá»ƒu thÃªm tá»« cÃ¡c trÆ°á»ng Ä‘áº¡i há»c cá»¥ thá»ƒ.', sources=[ToolOutput(content=\"{'program_name': None, 'score': 8, 'reasons': ['GPA Ä‘áº¡t yÃªu cáº§u', 'Trong ngÃ¢n sÃ¡ch']}\", tool_name='ScoreProgram', raw_input={'args': (), 'kwargs': {'user_gpa': 3.0, 'desired_program': 'Kinh táº¿', 'budget': 10000000, 'location_pref': 'HÃ  Ná»™i', 'candidate_program': AttributedDict()}}, raw_output={'program_name': None, 'score': 8, 'reasons': ['GPA Ä‘áº¡t yÃªu cáº§u', 'Trong ngÃ¢n sÃ¡ch']}, is_error=False)], source_nodes=[], is_dummy_stream=False, metadata=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple Agentic RAG vá»›i Tools vÃ  Memory - LlamaIndex 0.12+\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings, Document\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata, FunctionTool\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# Setup LLM vÃ  Embeddings\n",
    "Settings.llm = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-4\")\n",
    "Settings.embed_model = OpenAIEmbedding(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# # Táº¡o sample documents\n",
    "# docs = [\n",
    "#     Document(text=\"Äáº¡i há»c BÃ¡ch Khoa HN: cutoff_gpa=8.5, tuition_per_month=2000000, location='HÃ  Ná»™i', programs=['CÃ´ng nghá»‡ thÃ´ng tin', 'CÆ¡ khÃ­', 'Äiá»‡n tá»­']\"),\n",
    "#     Document(text=\"Äáº¡i há»c Kinh táº¿ Quá»‘c dÃ¢n: cutoff_gpa=7.8, tuition_per_month=1500000, location='HÃ  Ná»™i', programs=['Kinh táº¿', 'TÃ i chÃ­nh', 'Marketing']\"),\n",
    "#     Document(text=\"Äáº¡i há»c FPT: cutoff_gpa=6.5, tuition_per_month=3000000, location='TP.HCM', programs=['CNTT', 'Kinh doanh', 'Thiáº¿t káº¿']\"),\n",
    "# ]\n",
    "\n",
    "# # Táº¡o Vector Index vÃ  Query Engine\n",
    "# index = VectorStoreIndex.from_documents(docs)\n",
    "\n",
    "index_dsdaihoc = LlamaCloudIndex(\n",
    "        name=\"dsdaihoc\",\n",
    "        project_name=\"Default\",\n",
    "        organization_id=\"1bcf5fb2-bd7d-4c76-b6d5-bb793486e1b3\",\n",
    "        api_key=os.getenv(\"LLAMA_CLOUD_API_KEY\"),\n",
    "        )\n",
    "# 3ï¸âƒ£ Build query engine (RAG engine)\n",
    "\n",
    "query_engine = index_dsdaihoc.as_query_engine(similarity_top_k=5)\n",
    "# query_engine = index.as_query_engine(similarity_top_k=2)\n",
    "\n",
    "# Tool cháº¥m Ä‘iá»ƒm chÆ°Æ¡ng trÃ¬nh Ä‘áº¡i há»c\n",
    "def score_program(user_gpa: float, desired_program: str, budget: float, location_pref: str, candidate_program: dict) -> dict:\n",
    "    score = 0\n",
    "    reasons = []\n",
    "    if user_gpa >= candidate_program.get(\"cutoff_gpa\", 0):\n",
    "        score += 5; reasons.append(\"GPA Ä‘áº¡t yÃªu cáº§u\")\n",
    "    if candidate_program.get(\"tuition_per_month\", 0) / 1e6 <= budget:\n",
    "        score += 3; reasons.append(\"Trong ngÃ¢n sÃ¡ch\")\n",
    "    if location_pref.lower() in candidate_program.get(\"location\", \"\").lower():\n",
    "        score += 2; reasons.append(\"Gáº§n khu vá»±c\")\n",
    "    if desired_program.lower() in [p.lower() for p in candidate_program.get(\"programs\", [])]:\n",
    "        score += 4; reasons.append(\"CÃ³ ngÃ nh báº¡n muá»‘n\")\n",
    "    return {\n",
    "        \"program_name\": candidate_program.get(\"name\"),\n",
    "        \"score\": score,\n",
    "        \"reasons\": reasons\n",
    "    }\n",
    "\n",
    "# Setup Tools\n",
    "rag_tool = QueryEngineTool(\n",
    "    query_engine=query_engine,\n",
    "    metadata=ToolMetadata(name=\"knowledge_base\", description=\"Search knowledge base\")\n",
    ")\n",
    "\n",
    "score_tool = FunctionTool.from_defaults(\n",
    "    fn=score_program,\n",
    "    name=\"ScoreProgram\", \n",
    "    description=\"Cháº¥m Ä‘iá»ƒm chÆ°Æ¡ng trÃ¬nh Ä‘áº¡i há»c dá»±a trÃªn GPA, ngÃ nh, ngÃ¢n sÃ¡ch, nÆ¡i á»Ÿ\"\n",
    ")\n",
    "\n",
    "tools = [rag_tool, score_tool]\n",
    "\n",
    "# Setup Memory\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=2000)\n",
    "\n",
    "# Táº¡o Agent\n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    system_prompt=\"Báº¡n lÃ  trá»£ lÃ½ tÆ° váº¥n tuyá»ƒn sinh Ä‘áº¡i há»c. CÃ³ thá»ƒ tÃ¬m kiáº¿m thÃ´ng tin vÃ  cháº¥m Ä‘iá»ƒm chÆ°Æ¡ng trÃ¬nh há»c.\"\n",
    ")\n",
    "response =agent.chat(\"CÃ³ 10 triá»‡u 1 thÃ¡ng nÃªn há»c ngÃ nh kinh táº¿ nÃ o á»Ÿ HÃ  Ná»™i?\")\n",
    "# Chat function\n",
    "# def chat():\n",
    "#     print(\"ğŸ“ Trá»£ lÃ½ tÆ° váº¥n tuyá»ƒn sinh (type 'quit' to exit)\")\n",
    "#     while True:\n",
    "#         user_input = input(\"\\nğŸ‘¤ You: \")\n",
    "#         if user_input.lower() == 'quit':\n",
    "#             break\n",
    "        \n",
    "#         response = agent.chat(user_input)\n",
    "#         print(f\"ğŸ¤– Bot: {response}\")\n",
    "\n",
    "# # Run chat\n",
    "# if __name__ == \"__main__\":\n",
    "#     chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d9c1146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step dde6ceb7-44e5-420a-b24b-9f342772fba8. Step input: CÃ³ 10 triá»‡u 1 thÃ¡ng nÃªn há»c ngÃ nh kinh táº¿ nÃ o á»Ÿ HÃ  Ná»™i?\n",
      "\u001b[1;3;38;5;200mThought: The user is asking for a recommendation on which economics program to study in Hanoi with a budget of 10 million VND per month. I can use the ScoreProgram tool to provide a suitable recommendation based on the user's GPA, desired program, budget, and location preference.\n",
      "Action: ScoreProgram\n",
      "Action Input: {'user_gpa': 3.0, 'desired_program': 'Economics', 'budget': 10000000, 'location_pref': 'Hanoi', 'candidate_program': AttributedDict()}\n",
      "\u001b[0m\u001b[1;3;34mObservation: {'program_name': None, 'score': 8, 'reasons': ['GPA Ä‘áº¡t yÃªu cáº§u', 'Trong ngÃ¢n sÃ¡ch']}\n",
      "\u001b[0m> Running step a9337fd9-8fe8-449d-915b-4e982a1a3887. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The ScoreProgram tool has returned a score of 8, indicating that there are suitable economics programs in Hanoi within the user's budget. However, the tool did not provide a specific program name. I can answer without using any more tools.\n",
      "Answer: Vá»›i ngÃ¢n sÃ¡ch 10 triá»‡u VND má»—i thÃ¡ng, báº¡n hoÃ n toÃ n cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o ngÃ nh Kinh táº¿ á»Ÿ HÃ  Ná»™i phÃ¹ há»£p. Tuy nhiÃªn, Ä‘á»ƒ cÃ³ thÃ´ng tin cá»¥ thá»ƒ hÆ¡n, báº¡n nÃªn tÃ¬m hiá»ƒu thÃªm tá»« cÃ¡c trÆ°á»ng Ä‘áº¡i há»c cá»¥ thá»ƒ.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response =agent.chat(\"CÃ³ 10 triá»‡u 1 thÃ¡ng nÃªn há»c ngÃ nh kinh táº¿ nÃ o á»Ÿ HÃ  Ná»™i?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33287566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response='Vá»›i ngÃ¢n sÃ¡ch 10 triá»‡u VND má»—i thÃ¡ng, báº¡n hoÃ n toÃ n cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o ngÃ nh Kinh táº¿ á»Ÿ HÃ  Ná»™i phÃ¹ há»£p. Tuy nhiÃªn, Ä‘á»ƒ cÃ³ thÃ´ng tin cá»¥ thá»ƒ hÆ¡n, báº¡n nÃªn tÃ¬m hiá»ƒu thÃªm tá»« cÃ¡c trÆ°á»ng Ä‘áº¡i há»c cá»¥ thá»ƒ.', sources=[ToolOutput(content=\"{'program_name': None, 'score': 8, 'reasons': ['GPA Ä‘áº¡t yÃªu cáº§u', 'Trong ngÃ¢n sÃ¡ch']}\", tool_name='ScoreProgram', raw_input={'args': (), 'kwargs': {'user_gpa': 3.0, 'desired_program': 'Economics', 'budget': 10000000, 'location_pref': 'Hanoi', 'candidate_program': AttributedDict()}}, raw_output={'program_name': None, 'score': 8, 'reasons': ['GPA Ä‘áº¡t yÃªu cáº§u', 'Trong ngÃ¢n sÃ¡ch']}, is_error=False)], source_nodes=[], is_dummy_stream=False, metadata=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ab312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
