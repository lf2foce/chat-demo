import pandas as pd
import os
import re
from pathlib import Path
import json

class UniversityDataProcessor:
    def __init__(self, csv_path, output_dir="./docs_processed"):
        self.csv_path = csv_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
    def clean_text(self, text):
        """Clean and format text content"""
        if pd.isna(text) or text == '':
            return "Kh√¥ng c√≥ th√¥ng tin"
        
        # Convert to string and clean
        text = str(text).strip()
        
        # Fix common formatting issues
        text = re.sub(r'\n+', '\n', text)  # Multiple newlines to single
        text = re.sub(r'[ \t]+', ' ', text)  # Multiple spaces to single
        
        return text
    
    def parse_tags(self, tags_str):
        """Parse tags string into list"""
        if pd.isna(tags_str) or tags_str == '':
            return []
        
        # Remove brackets and quotes, split by comma
        tags_str = str(tags_str).strip('[]"\'')
        tags = [tag.strip().strip('"\'') for tag in tags_str.split(',')]
        return [tag for tag in tags if tag]
    
    def create_safe_filename(self, university_name, index):
        """Create safe filename from university name"""
        # Remove/replace special characters
        safe_name = re.sub(r'[^\w\s-]', '', university_name)
        safe_name = re.sub(r'[-\s]+', '_', safe_name)
        return f"{index+1:03d}_{safe_name}.md"
    
    def process_csv(self):
        """Main processing function"""
        print(f"üîÑ ƒêang x·ª≠ l√Ω file CSV: {self.csv_path}")
        
        # Read CSV with proper encoding
        try:
            df = pd.read_csv(self.csv_path, encoding='utf-8')
        except UnicodeDecodeError:
            df = pd.read_csv(self.csv_path, encoding='utf-8-sig')
        
        print(f"üìä T√¨m th·∫•y {len(df)} tr∆∞·ªùng ƒë·∫°i h·ªçc")
        
        # Create different output formats
        self.create_individual_files(df)
        self.create_comprehensive_file(df)
        self.create_search_optimized_files(df)
        
        print("‚úÖ Ho√†n th√†nh chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu!")
        return df
    
    def create_individual_files(self, df):
        """Create individual markdown files for each university"""
        individual_dir = self.output_dir / "universities"
        individual_dir.mkdir(exist_ok=True)
        
        for idx, row in df.iterrows():
            university_name = self.clean_text(row.get('T√™n tr∆∞·ªùng', ''))
            description = self.clean_text(row.get('M√¥ t·∫£ tr∆∞·ªùng', ''))
            changes_2025 = self.clean_text(row.get('Thay ƒë·ªïi 2025', ''))
            admission_info = self.clean_text(row.get('Th√¥ng tin tr∆∞·ªùng', ''))
            programs = self.clean_text(row.get('Ch∆∞∆°ng tr√¨nh', ''))
            admission_scores = self.clean_text(row.get('ƒêi·ªÉm chu·∫©n ', ''))  # Note the space
            tags = self.parse_tags(row.get('Tags', ''))
            
            filename = self.create_safe_filename(university_name, idx)
            
            content = f"""# {university_name}

## Th√¥ng tin t·ªïng quan
{description}

## Nh·ªØng thay ƒë·ªïi v√† c·∫≠p nh·∫≠t nƒÉm 2025
{changes_2025}

## Th√¥ng tin tuy·ªÉn sinh v√† x√©t tuy·ªÉn
{admission_info}

## C√°c ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o v√† h·ªçc ph√≠
{programs}

## ƒêi·ªÉm chu·∫©n tham kh·∫£o
{admission_scores}

## T·ª´ kh√≥a v√† ƒë·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t
{', '.join(tags) if tags else 'Kh√¥ng c√≥ th√¥ng tin'}

---

**Metadata:**
- **Lo·∫°i tr∆∞·ªùng:** {'C√¥ng l·∫≠p' if 'C√¥ng l·∫≠p' in tags else 'T∆∞ th·ª•c' if 'T∆∞ th·ª•c' in tags else 'Kh√¥ng x√°c ƒë·ªãnh'}
- **Khu v·ª±c:** {self.extract_location(tags, university_name)}
- **Lƒ©nh v·ª±c:** {self.extract_field(tags, university_name)}
- **NƒÉm c·∫≠p nh·∫≠t:** 2025
- **Ngu·ªìn:** D·ªØ li·ªáu tuy·ªÉn sinh ch√≠nh th·ª©c

**C√°c t·ª´ kh√≥a t√¨m ki·∫øm:**
{', '.join(tags + [university_name.split()[0], university_name.split()[-1]] if len(university_name.split()) > 1 else tags + [university_name])}
"""
            
            with open(individual_dir / filename, "w", encoding="utf-8") as f:
                f.write(content)
    
    def create_comprehensive_file(self, df):
        """Create one comprehensive file with all universities"""
        content = """# C·∫©m nang Tuy·ªÉn sinh ƒê·∫°i h·ªçc Vi·ªát Nam 2025

T√†i li·ªáu n√†y t·ªïng h·ª£p th√¥ng tin chi ti·∫øt v·ªÅ c√°c tr∆∞·ªùng ƒë·∫°i h·ªçc t·∫°i Vi·ªát Nam, bao g·ªìm th√¥ng tin tuy·ªÉn sinh, ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o, ƒëi·ªÉm chu·∫©n v√† nh·ªØng thay ƒë·ªïi m·ªõi nh·∫•t nƒÉm 2025.

---

"""
        
        for idx, row in df.iterrows():
            university_name = self.clean_text(row.get('T√™n tr∆∞·ªùng', ''))
            description = self.clean_text(row.get('M√¥ t·∫£ tr∆∞·ªùng', ''))
            changes_2025 = self.clean_text(row.get('Thay ƒë·ªïi 2025', ''))
            admission_info = self.clean_text(row.get('Th√¥ng tin tr∆∞·ªùng', ''))
            programs = self.clean_text(row.get('Ch∆∞∆°ng tr√¨nh', ''))
            admission_scores = self.clean_text(row.get('ƒêi·ªÉm chu·∫©n ', ''))
            tags = self.parse_tags(row.get('Tags', ''))
            
            content += f"""
## {idx + 1}. {university_name}

### üìã Th√¥ng tin c∆° b·∫£n
{description}

### üîÑ C·∫≠p nh·∫≠t nƒÉm 2025
{changes_2025}

### üéì Tuy·ªÉn sinh v√† x√©t tuy·ªÉn
{admission_info}

### üìö Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o
{programs}

### üìä ƒêi·ªÉm chu·∫©n
{admission_scores}

### üè∑Ô∏è ƒê·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t
- **Lo·∫°i h√¨nh:** {'C√¥ng l·∫≠p' if 'C√¥ng l·∫≠p' in tags else 'T∆∞ th·ª•c' if 'T∆∞ th·ª•c' in tags else 'Kh√¥ng x√°c ƒë·ªãnh'}
- **Lƒ©nh v·ª±c m·∫°nh:** {', '.join([tag for tag in tags if tag not in ['C√¥ng l·∫≠p', 'T∆∞ th·ª•c']])}

---

"""
        
        with open(self.output_dir / "cam_nang_tuyen_sinh_2025.md", "w", encoding="utf-8") as f:
            f.write(content)
    
    def create_search_optimized_files(self, df):
        """Create search-optimized files by category"""
        search_dir = self.output_dir / "by_category"
        search_dir.mkdir(exist_ok=True)
        
        # Group by location
        self.create_location_files(df, search_dir)
        
        # Group by field
        self.create_field_files(df, search_dir)
        
        # Create admission scores summary
        self.create_scores_summary(df, search_dir)
    
    def create_location_files(self, df, search_dir):
        """Create files grouped by location"""
        location_groups = {}
        
        for idx, row in df.iterrows():
            university_name = self.clean_text(row.get('T√™n tr∆∞·ªùng', ''))
            tags = self.parse_tags(row.get('Tags', ''))
            location = self.extract_location(tags, university_name)
            
            if location not in location_groups:
                location_groups[location] = []
            location_groups[location].append((idx, row))
        
        for location, universities in location_groups.items():
            content = f"""# C√°c tr∆∞·ªùng ƒë·∫°i h·ªçc t·∫°i {location}

Danh s√°ch c√°c tr∆∞·ªùng ƒë·∫°i h·ªçc v√† th√¥ng tin tuy·ªÉn sinh t·∫°i khu v·ª±c {location} nƒÉm 2025.

"""
            
            for idx, row in universities:
                university_name = self.clean_text(row.get('T√™n tr∆∞·ªùng', ''))
                description = self.clean_text(row.get('M√¥ t·∫£ tr∆∞·ªùng', ''))
                admission_scores = self.clean_text(row.get('ƒêi·ªÉm chu·∫©n ', ''))
                
                content += f"""
## {university_name}

{description[:300]}...

**ƒêi·ªÉm chu·∫©n 2024:** {admission_scores.split('.')[0] if admission_scores != 'Kh√¥ng c√≥ th√¥ng tin' else 'Ch∆∞a c√¥ng b·ªë'}

---
"""
            
            safe_location = re.sub(r'[^\w\s-]', '', location).replace(' ', '_')
            with open(search_dir / f"truong_dai_hoc_{safe_location.lower()}.md", "w", encoding="utf-8") as f:
                f.write(content)
    
    def create_field_files(self, df, search_dir):
        """Create files grouped by field of study"""
        field_groups = {}
        
        for idx, row in df.iterrows():
            university_name = self.clean_text(row.get('T√™n tr∆∞·ªùng', ''))
            tags = self.parse_tags(row.get('Tags', ''))
            field = self.extract_field(tags, university_name)
            
            if field not in field_groups:
                field_groups[field] = []
            field_groups[field].append((idx, row))
        
        for field, universities in field_groups.items():
            content = f"""# C√°c tr∆∞·ªùng ƒë·∫°i h·ªçc {field}

Danh s√°ch c√°c tr∆∞·ªùng ƒë·∫°i h·ªçc chuy√™n v·ªÅ {field.lower()} v√† th√¥ng tin tuy·ªÉn sinh nƒÉm 2025.

"""
            
            for idx, row in universities:
                university_name = self.clean_text(row.get('T√™n tr∆∞·ªùng', ''))
                programs = self.clean_text(row.get('Ch∆∞∆°ng tr√¨nh', ''))
                admission_scores = self.clean_text(row.get('ƒêi·ªÉm chu·∫©n ', ''))
                
                content += f"""
## {university_name}

**Ch∆∞∆°ng tr√¨nh n·ªïi b·∫≠t:** {programs[:200]}...

**ƒêi·ªÉm chu·∫©n:** {admission_scores.split('\n')[0] if admission_scores != 'Kh√¥ng c√≥ th√¥ng tin' else 'Ch∆∞a c√¥ng b·ªë'}

---
"""
            
            safe_field = re.sub(r'[^\w\s-]', '', field).replace(' ', '_')
            with open(search_dir / f"nganh_{safe_field.lower()}.md", "w", encoding="utf-8") as f:
                f.write(content)
    
    def create_scores_summary(self, df, search_dir):
        """Create admission scores summary"""
        content = """# T·ªïng h·ª£p ƒêi·ªÉm chu·∫©n ƒê·∫°i h·ªçc 2024

B·∫£ng t·ªïng h·ª£p ƒëi·ªÉm chu·∫©n c√°c tr∆∞·ªùng ƒë·∫°i h·ªçc nƒÉm 2024 ƒë·ªÉ tham kh·∫£o cho k·ª≥ tuy·ªÉn sinh 2025.

"""
        
        scores_data = []
        
        for idx, row in df.iterrows():
            university_name = self.clean_text(row.get('T√™n tr∆∞·ªùng', ''))
            admission_scores = self.clean_text(row.get('ƒêi·ªÉm chu·∫©n ', ''))
            tags = self.parse_tags(row.get('Tags', ''))
            
            # Extract highest score for sorting
            score_numbers = re.findall(r'(\d+[,.]?\d*)', admission_scores)
            highest_score = 0
            if score_numbers:
                try:
                    highest_score = max([float(s.replace(',', '.')) for s in score_numbers])
                except:
                    highest_score = 0
            
            scores_data.append({
                'name': university_name,
                'scores': admission_scores,
                'highest': highest_score,
                'field': self.extract_field(tags, university_name)
            })
        
        # Sort by highest score
        scores_data.sort(key=lambda x: x['highest'], reverse=True)
        
        for data in scores_data:
            content += f"""
## {data['name']}
- **Lƒ©nh v·ª±c:** {data['field']}
- **ƒêi·ªÉm chu·∫©n cao nh·∫•t:** {data['highest']} ƒëi·ªÉm
- **Chi ti·∫øt:** {data['scores'][:150]}...

---
"""
        
        with open(search_dir / "diem_chuan_2024.md", "w", encoding="utf-8") as f:
            f.write(content)
    
    def extract_location(self, tags, university_name):
        """Extract location from tags or university name"""
        location_keywords = {
            'H·ªì Ch√≠ Minh': ['H·ªì Ch√≠ Minh', 'TP.HCM', 'TPHCM', 'S√†i G√≤n'],
            'H√† N·ªôi': ['H√† N·ªôi', 'Hanoi'],
            'ƒê√† N·∫µng': ['ƒê√† N·∫µng', 'Da Nang'],
            'C·∫ßn Th∆°': ['C·∫ßn Th∆°', 'Can Tho'],
            'Hu·∫ø': ['Hu·∫ø', 'Hue'],
        }
        
        # Check tags first
        for location, keywords in location_keywords.items():
            for keyword in keywords:
                if any(keyword.lower() in tag.lower() for tag in tags):
                    return location
        
        # Check university name
        for location, keywords in location_keywords.items():
            for keyword in keywords:
                if keyword.lower() in university_name.lower():
                    return location
        
        return 'C√°c t·ªânh th√†nh kh√°c'
    
    def extract_field(self, tags, university_name):
        """Extract field of study from tags or university name"""
        field_keywords = {
            'C√¥ng ngh·ªá - K·ªπ thu·∫≠t': ['C√¥ng ngh·ªá', 'K·ªπ thu·∫≠t', 'C√¥ng nghi·ªáp', 'ƒêi·ªán', 'C∆° kh√≠'],
            'Y - D∆∞·ª£c': ['Y khoa', 'Y t·∫ø', 'D∆∞·ª£c', 'Y h·ªçc'],
            'Kinh t·∫ø - Qu·∫£n tr·ªã': ['Kinh t·∫ø', 'Qu·∫£n tr·ªã', 'T√†i ch√≠nh', 'Ng√¢n h√†ng'],
            'S∆∞ ph·∫°m - Gi√°o d·ª•c': ['S∆∞ ph·∫°m', 'Gi√°o d·ª•c', 'ƒê√†o t·∫°o'],
            'N√¥ng - L√¢m - Ng∆∞': ['N√¥ng nghi·ªáp', 'L√¢m nghi·ªáp', 'Th·ªßy s·∫£n'],
        }
        
        # Check tags first
        for field, keywords in field_keywords.items():
            for keyword in keywords:
                if any(keyword.lower() in tag.lower() for tag in tags):
                    return field
        
        # Check university name
        for field, keywords in field_keywords.items():
            for keyword in keywords:
                if keyword.lower() in university_name.lower():
                    return field
        
        return 'ƒêa ng√†nh'

# Usage
if __name__ == "__main__":
    # Initialize processor
    processor = UniversityDataProcessor("../notebook/Tr∆∞·ªùng-Grid view (2).csv")  # Update path as needed
    
    # Process the CSV
    df = processor.process_csv()
    
    print(f"\nüìÅ C√°c file ƒë√£ ƒë∆∞·ª£c t·∫°o trong th∆∞ m·ª•c: {processor.output_dir}")
    print("üìÇ C·∫•u tr√∫c th∆∞ m·ª•c:")
    print("   ‚îú‚îÄ‚îÄ universities/           # File ri√™ng cho t·ª´ng tr∆∞·ªùng")
    print("   ‚îú‚îÄ‚îÄ by_category/           # File theo danh m·ª•c")
    print("   ‚îî‚îÄ‚îÄ cam_nang_tuyen_sinh_2025.md  # File t·ªïng h·ª£p")